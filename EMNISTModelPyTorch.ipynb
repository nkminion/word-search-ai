{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "235befc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch is using the GPU\n",
      "Found 1 GPUs\n",
      "GPU 0 found: NVIDIA GeForce RTX 5070 Laptop GPU\n",
      "Selected Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "#Importing packages and checking GPU\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchsummary import summary \n",
    "\n",
    "if torch.cuda.is_available():\n",
    "\tprint(\"PyTorch is using the GPU\")\n",
    "\tGPUCount = torch.cuda.device_count()\n",
    "\tprint(f\"Found {GPUCount} GPUs\")\n",
    "\n",
    "\tfor i in range(GPUCount):\n",
    "\t\tprint(f\"GPU {i} found: {torch.cuda.get_device_name(i)}\")\n",
    "\n",
    "\tdevice = torch.device(\"cuda:0\")\n",
    "else:\n",
    "\tprint(\"PyTorch is using the CPU\")\n",
    "\tdevice = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Selected Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e172ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set size: 124800 | Test Set size: 20800\n"
     ]
    }
   ],
   "source": [
    "#Load BuiltIn dataset\n",
    "Transform = transforms.Compose(\n",
    "\t[transforms.ToTensor(),\n",
    "  transforms.Normalize((0.5,),(0.5,))])\n",
    "Transform = transforms.Compose(\n",
    "\t[transforms.ToTensor(),\n",
    "  transforms.Normalize((0.5,),(0.5,))])\n",
    "\n",
    "TrainSet = torchvision.datasets.EMNIST(root='./data',train=True,download=True,transform=Transform,split=\"letters\",target_transform=lambda y:y-1)\n",
    "TrainLoader = DataLoader(TrainSet, batch_size=128, shuffle=True)\n",
    "\n",
    "TestSet = torchvision.datasets.EMNIST(root='./data',train=False,download=True,transform=Transform,split=\"letters\",target_transform=lambda y:y-1)\n",
    "TestLoader = DataLoader(TestSet, batch_size=128, shuffle=False)\n",
    "\n",
    "print(f\"Training Set size: {len(TrainSet)} | Test Set size: {len(TestSet)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3889778c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating EMNIST Model...\n",
      "Model Created\n",
      "Model Summary: \n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 28, 28]             288\n",
      "       BatchNorm2d-2           [-1, 32, 28, 28]              64\n",
      "              ReLU-3           [-1, 32, 28, 28]               0\n",
      "         MaxPool2d-4           [-1, 32, 14, 14]               0\n",
      "            Conv2d-5           [-1, 32, 14, 14]           9,216\n",
      "       BatchNorm2d-6           [-1, 32, 14, 14]              64\n",
      "              ReLU-7           [-1, 32, 14, 14]               0\n",
      "            Conv2d-8           [-1, 64, 14, 14]          18,432\n",
      "       BatchNorm2d-9           [-1, 64, 14, 14]             128\n",
      "             ReLU-10           [-1, 64, 14, 14]               0\n",
      "           Conv2d-11           [-1, 64, 14, 14]          36,864\n",
      "      BatchNorm2d-12           [-1, 64, 14, 14]             128\n",
      "             ReLU-13           [-1, 64, 14, 14]               0\n",
      "           Conv2d-14           [-1, 64, 14, 14]          36,864\n",
      "      BatchNorm2d-15           [-1, 64, 14, 14]             128\n",
      "             ReLU-16           [-1, 64, 14, 14]               0\n",
      "        MaxPool2d-17             [-1, 64, 7, 7]               0\n",
      "          Flatten-18                 [-1, 3136]               0\n",
      "           Linear-19                   [-1, 64]         200,768\n",
      "             ReLU-20                   [-1, 64]               0\n",
      "           Linear-21                   [-1, 64]           4,160\n",
      "             ReLU-22                   [-1, 64]               0\n",
      "          Dropout-23                   [-1, 64]               0\n",
      "           Linear-24                   [-1, 26]           1,690\n",
      "================================================================\n",
      "Total params: 308,794\n",
      "Trainable params: 308,794\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 1.68\n",
      "Params size (MB): 1.18\n",
      "Estimated Total Size (MB): 2.86\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Creating Model\n",
    "\n",
    "#Define architecture\n",
    "class EMNISTModel(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(EMNISTModel,self).__init__()\n",
    "\n",
    "\t\t#Layer1\n",
    "\t\tself.conv1 = nn.Conv2d(in_channels=1,out_channels=32,kernel_size=3,padding=1,bias=False)#Size does not change\n",
    "\t\tself.bn1 = nn.BatchNorm2d(num_features=32)\n",
    "\t\tself.relu1 = nn.ReLU()\n",
    "\t\tself.pool1 = nn.MaxPool2d(kernel_size=2)#Size halves into 14x14\n",
    "\n",
    "\t\t#Layer2\n",
    "\t\tself.conv2 = nn.Conv2d(in_channels=32,out_channels=32,kernel_size=3,padding=1,bias=False)\n",
    "\t\tself.bn2 = nn.BatchNorm2d(num_features=32)\n",
    "\t\tself.relu2 = nn.ReLU()\n",
    "\n",
    "\t\t#Layer3\n",
    "\t\tself.conv3 = nn.Conv2d(in_channels=32,out_channels=64,kernel_size=3,padding=1,bias=False)\n",
    "\t\tself.bn3 = nn.BatchNorm2d(num_features=64)\n",
    "\t\tself.relu3 = nn.ReLU()\n",
    "\n",
    "\t\t#Layer4\n",
    "\t\tself.conv4 = nn.Conv2d(in_channels=64,out_channels=64,kernel_size=3,padding=1,bias=False)\n",
    "\t\tself.bn4 = nn.BatchNorm2d(num_features=64)\n",
    "\t\tself.relu4 = nn.ReLU()\n",
    "\n",
    "\t\t#Layer5\n",
    "\t\tself.conv5 = nn.Conv2d(in_channels=64,out_channels=64,kernel_size=3,padding=1,bias=False)\n",
    "\t\tself.bn5 = nn.BatchNorm2d(num_features=64)\n",
    "\t\tself.relu5 = nn.ReLU()\n",
    "\t\tself.pool2 = nn.MaxPool2d(kernel_size=2)#Size halves into 7x7\n",
    "\n",
    "\t\t#FlattenLayer\n",
    "\t\tself.flatten = nn.Flatten()\n",
    "\n",
    "\t\t#Layer6\n",
    "\t\tself.fc1 = nn.Linear(in_features=64*7*7,out_features=64)\n",
    "\t\tself.relu6 = nn.ReLU()\n",
    "\n",
    "\t\t#Layer7\n",
    "\t\tself.fc2 = nn.Linear(in_features=64,out_features=64)\n",
    "\t\tself.relu7 = nn.ReLU()\n",
    "\n",
    "\t\t#DropoutLayer\n",
    "\t\tself.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "\t\t#Layer8\n",
    "\t\tself.fc3 = nn.Linear(in_features=64,out_features=26)\n",
    "\n",
    "\tdef forward(self,x):\n",
    "\n",
    "\t\t#Pass through Layer1\n",
    "\t\tx = self.pool1(self.relu1(self.bn1(self.conv1(x))))\n",
    "\n",
    "\t\t#Pass through Layer2\n",
    "\t\tx = self.relu2(self.bn2(self.conv2(x)))\n",
    "\n",
    "\t\t#Pass through Layer3\n",
    "\t\tx = self.relu3(self.bn3(self.conv3(x)))\n",
    "\n",
    "\t\t#Pass through Layer4\n",
    "\t\tx = self.relu4(self.bn4(self.conv4(x)))\n",
    "\n",
    "\t\t#Pass through Layer5\n",
    "\t\tx = self.pool2(self.relu5(self.bn5(self.conv5(x))))\n",
    "\n",
    "\t\t#Pass through Layer5\n",
    "\t\tx = self.flatten(x)\n",
    "\n",
    "\t\t#Pass through Layer6\n",
    "\t\tx = self.relu6(self.fc1(x))\n",
    "\n",
    "\t\t#Pass through Layer7\n",
    "\t\tx = self.relu7(self.fc2(x))\n",
    "\n",
    "\t\t#Pass through DropoutLayer\n",
    "\t\tx = self.dropout(x)\n",
    "\n",
    "\t\t#Pass through Layer7\n",
    "\t\tx = self.fc3(x)\n",
    "\n",
    "\t\t#Return Prediction\n",
    "\t\treturn x\n",
    "\n",
    "#Create and print summary\t\n",
    "print(\"Creating EMNIST Model...\")\n",
    "model = EMNISTModel().to(device)\n",
    "print(\"Model Created\")\n",
    "\n",
    "print(\"Model Summary: \")\n",
    "summary(model,input_size=(1,28,28))\n",
    "\n",
    "#Compile model\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "360e44df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model...\n",
      "Epoch: 1/100 | Training Loss: 0.465 | Validation Loss: 0.234 | Accuracy: 92.226%\n",
      "Accuracy has improved at epoch 1. Model Saved!\n",
      "Epoch: 2/100 | Training Loss: 0.232 | Validation Loss: 0.202 | Accuracy: 93.365%\n",
      "Accuracy has improved at epoch 2. Model Saved!\n",
      "Epoch: 3/100 | Training Loss: 0.201 | Validation Loss: 0.182 | Accuracy: 93.894%\n",
      "Accuracy has improved at epoch 3. Model Saved!\n",
      "Epoch: 4/100 | Training Loss: 0.185 | Validation Loss: 0.178 | Accuracy: 93.966%\n",
      "Accuracy has improved at epoch 4. Model Saved!\n",
      "Epoch: 5/100 | Training Loss: 0.169 | Validation Loss: 0.184 | Accuracy: 93.899%\n",
      "Accuracy has not improved. Patience:1/5\n",
      "Epoch: 6/100 | Training Loss: 0.160 | Validation Loss: 0.171 | Accuracy: 94.375%\n",
      "Accuracy has improved at epoch 6. Model Saved!\n",
      "Epoch: 7/100 | Training Loss: 0.150 | Validation Loss: 0.174 | Accuracy: 94.183%\n",
      "Accuracy has not improved. Patience:1/5\n",
      "Epoch: 8/100 | Training Loss: 0.142 | Validation Loss: 0.167 | Accuracy: 94.399%\n",
      "Accuracy has improved at epoch 8. Model Saved!\n",
      "Epoch: 9/100 | Training Loss: 0.136 | Validation Loss: 0.172 | Accuracy: 94.486%\n",
      "Accuracy has improved at epoch 9. Model Saved!\n",
      "Epoch: 10/100 | Training Loss: 0.129 | Validation Loss: 0.176 | Accuracy: 94.495%\n",
      "Accuracy has improved at epoch 10. Model Saved!\n",
      "Epoch: 11/100 | Training Loss: 0.123 | Validation Loss: 0.177 | Accuracy: 94.346%\n",
      "Accuracy has not improved. Patience:1/5\n",
      "Epoch: 12/100 | Training Loss: 0.116 | Validation Loss: 0.173 | Accuracy: 94.538%\n",
      "Accuracy has improved at epoch 12. Model Saved!\n",
      "Epoch: 13/100 | Training Loss: 0.112 | Validation Loss: 0.185 | Accuracy: 94.322%\n",
      "Accuracy has not improved. Patience:1/5\n",
      "Epoch: 14/100 | Training Loss: 0.107 | Validation Loss: 0.178 | Accuracy: 94.423%\n",
      "Accuracy has not improved. Patience:2/5\n",
      "Epoch: 15/100 | Training Loss: 0.102 | Validation Loss: 0.185 | Accuracy: 94.452%\n",
      "Accuracy has not improved. Patience:3/5\n",
      "Epoch: 16/100 | Training Loss: 0.098 | Validation Loss: 0.176 | Accuracy: 94.615%\n",
      "Accuracy has improved at epoch 16. Model Saved!\n",
      "Epoch: 17/100 | Training Loss: 0.094 | Validation Loss: 0.181 | Accuracy: 94.702%\n",
      "Accuracy has improved at epoch 17. Model Saved!\n",
      "Epoch: 18/100 | Training Loss: 0.090 | Validation Loss: 0.181 | Accuracy: 94.606%\n",
      "Accuracy has not improved. Patience:1/5\n",
      "Epoch: 19/100 | Training Loss: 0.087 | Validation Loss: 0.190 | Accuracy: 94.548%\n",
      "Accuracy has not improved. Patience:2/5\n",
      "Epoch: 20/100 | Training Loss: 0.086 | Validation Loss: 0.191 | Accuracy: 94.625%\n",
      "Accuracy has not improved. Patience:3/5\n",
      "Epoch: 21/100 | Training Loss: 0.080 | Validation Loss: 0.198 | Accuracy: 94.591%\n",
      "Accuracy has not improved. Patience:4/5\n",
      "Epoch: 22/100 | Training Loss: 0.078 | Validation Loss: 0.206 | Accuracy: 94.466%\n",
      "Accuracy has not improved. Patience:5/5\n",
      "Early stopping triggered!\n",
      "Training Complete\n"
     ]
    }
   ],
   "source": [
    "#Training and saving the model\n",
    "\n",
    "print(\"Training Model...\")\n",
    "epochs = 100\n",
    "patience = 5\n",
    "counter = 0\n",
    "MaxAccuracy = float('-inf')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\t#Train Loop\n",
    "\n",
    "\t#Set model to training mode\n",
    "\tmodel.train()\n",
    "\tTrainLoss = 0.0\n",
    "\n",
    "\tfor i,data in enumerate(TrainLoader,0):\n",
    "\t\tinputs,labels = data[0].to(device),data[1].to(device)\n",
    "\n",
    "\t\t#Zero the parameter gradients\n",
    "\t\toptimizer.zero_grad()\n",
    "\n",
    "\t\t#Forward pass\n",
    "\t\toutputs = model(inputs)\n",
    "\n",
    "\t\t#Calculate loss\n",
    "\t\tloss = loss_function(outputs,labels)\n",
    "\n",
    "\t\t#Backward pass\n",
    "\t\tloss.backward()\n",
    "\n",
    "\t\t#Update weights\n",
    "\t\toptimizer.step()\n",
    "\n",
    "\t\t#Update loss\n",
    "\t\tTrainLoss += loss.item()\n",
    "\t\n",
    "\t#Validation Loop\n",
    "\tmodel.eval()\n",
    "\tValidationLoss = 0.0\n",
    "\tcorrect = 0\n",
    "\ttotal = 0\n",
    "\n",
    "\twith torch.no_grad():\n",
    "\t\tfor data in TestLoader:\n",
    "\t\t\timages,labels = data[0].to(device),data[1].to(device)\n",
    "\t\t\toutputs = model(images)\n",
    "\t\t\tloss = loss_function(outputs,labels)\n",
    "\t\t\tValidationLoss += loss.item()\n",
    "\n",
    "\t\t\t_,predicted = torch.max(outputs.data,1)\n",
    "\t\t\ttotal += labels.size(0)\n",
    "\t\t\tcorrect += (predicted == labels).sum().item()\n",
    "\n",
    "\t\tacc = 100*correct/total\n",
    "\t\tprint(f\"Epoch: {epoch+1}/{epochs} | \"\n",
    "\t\t\tf\"Training Loss: {TrainLoss/len(TrainLoader):.3f} | \"\n",
    "\t\t\tf\"Validation Loss: {ValidationLoss / len(TestLoader):.3f} | \"\n",
    "\t\t\tf\"Accuracy: {acc:.3f}%\")\n",
    "\t\t\n",
    "\t\tif acc > MaxAccuracy:\n",
    "\t\t\tMaxAccuracy = acc\n",
    "\t\t\tcounter = 0\n",
    "\t\t\ttorch.save(model.state_dict(),\"EMNISTModel.pth\")\n",
    "\t\t\tprint(f\"Accuracy has improved at epoch {epoch+1}. Model Saved!\")\n",
    "\t\telse:\n",
    "\t\t\tcounter += 1\n",
    "\t\t\tprint(f\"Accuracy has not improved. Patience:{counter}/{patience}\")\n",
    "\t\t\n",
    "\t\tif counter >= patience:\n",
    "\t\t\tprint(\"Early stopping triggered!\")\n",
    "\t\t\tbreak\n",
    "\t\t\n",
    "print(\"Training Complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b2021dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model with inbuilt dataset...\n",
      "Test Accuracy: 94.702%\n",
      "Test Loss: 0.181\n"
     ]
    }
   ],
   "source": [
    "#Testing Model\n",
    "\n",
    "print(\"Testing model with inbuilt dataset...\")\n",
    "\n",
    "model.load_state_dict(torch.load(\"EMNISTModel.pth\"))\n",
    "\n",
    "TestLoss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "\tfor images, labels in TestLoader:\n",
    "\n",
    "\t\t#Move data to device\n",
    "\t\timages,labels = images.to(device),labels.to(device)\n",
    "\n",
    "\t\t#Forward pass\n",
    "\t\toutputs = model(images)\n",
    "\n",
    "\t\t#Calculate loss\n",
    "\t\tloss = loss_function(outputs,labels)\n",
    "\t\tTestLoss += loss.item()\n",
    "\n",
    "\t\t#Get predicted class\n",
    "\t\t_,predicted = torch.max(outputs.data,1)\n",
    "\n",
    "\t\t#Update total and correct counts\n",
    "\t\ttotal += labels.size(0)\n",
    "\t\tcorrect += (predicted == labels).sum().item()\n",
    "\t\n",
    "#Test Results\n",
    "\n",
    "FinalLoss = TestLoss/len(TestLoader)\n",
    "FinalAcc = 100*correct/total\n",
    "\n",
    "print(f\"Test Accuracy: {FinalAcc:.3f}%\")\n",
    "print(f\"Test Loss: {FinalLoss:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
