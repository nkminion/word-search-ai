{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "235befc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch is using the GPU\n",
      "Found 1 GPUs\n",
      "GPU 0 found: NVIDIA GeForce RTX 5070 Laptop GPU\n",
      "Selected Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "#Importing packages and checking GPU\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchsummary import summary\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "\tprint(\"PyTorch is using the GPU\")\n",
    "\tGPUCount = torch.cuda.device_count()\n",
    "\tprint(f\"Found {GPUCount} GPUs\")\n",
    "\n",
    "\tfor i in range(GPUCount):\n",
    "\t\tprint(f\"GPU {i} found: {torch.cuda.get_device_name(i)}\")\n",
    "\n",
    "\tdevice = torch.device(\"cuda:0\")\n",
    "else:\n",
    "\tprint(\"PyTorch is using the CPU\")\n",
    "\tdevice = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Selected Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e172ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load BuiltIn dataset\n",
    "Transform = transforms.Compose(\n",
    "\t[transforms.ToTensor(),\n",
    "  transforms.Normalize((0.5,),(0.5,))])\n",
    "Transform = transforms.Compose(\n",
    "\t[transforms.ToTensor(),\n",
    "  transforms.Normalize((0.5,),(0.5,))])\n",
    "\n",
    "TrainSet = torchvision.datasets.EMNIST(root='./data',train=True,download=True,transform=Transform,split=\"letters\",target_transform=lambda y:y-1)\n",
    "TrainLoader = DataLoader(TrainSet, batch_size=128, shuffle=True)\n",
    "\n",
    "TestSet = torchvision.datasets.EMNIST(root='./data',train=False,download=True,transform=Transform,split=\"letters\",target_transform=lambda y:y-1)\n",
    "TestLoader = DataLoader(TestSet, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3889778c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating EMNIST Model...\n",
      "Model Created\n",
      "Model Summary: \n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 26, 26]             320\n",
      "              ReLU-2           [-1, 32, 26, 26]               0\n",
      "         MaxPool2d-3           [-1, 32, 13, 13]               0\n",
      "            Conv2d-4           [-1, 64, 11, 11]          18,496\n",
      "              ReLU-5           [-1, 64, 11, 11]               0\n",
      "         MaxPool2d-6             [-1, 64, 5, 5]               0\n",
      "            Conv2d-7             [-1, 64, 3, 3]          36,928\n",
      "           Flatten-8                  [-1, 576]               0\n",
      "            Linear-9                   [-1, 64]          36,928\n",
      "             ReLU-10                   [-1, 64]               0\n",
      "           Linear-11                   [-1, 26]           1,690\n",
      "================================================================\n",
      "Total params: 94,362\n",
      "Trainable params: 94,362\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.51\n",
      "Params size (MB): 0.36\n",
      "Estimated Total Size (MB): 0.87\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Creating Model\n",
    "\n",
    "#Define architecture\n",
    "class EMNISTModel(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(EMNISTModel,self).__init__()\n",
    "\n",
    "\t\t#Layer1\n",
    "\t\tself.conv1 = nn.Conv2d(in_channels=1,out_channels=32,kernel_size=3)#Size does not change\n",
    "\t\tself.relu1 = nn.ReLU()\n",
    "\t\tself.pool1 = nn.MaxPool2d(kernel_size=2)#Size halves into 14x14\n",
    "\n",
    "\t\t#Layer2\n",
    "\t\tself.conv2 = nn.Conv2d(in_channels=32,out_channels=64,kernel_size=3)\n",
    "\t\tself.relu2 = nn.ReLU()\n",
    "\t\tself.pool2 = nn.MaxPool2d(kernel_size=2)#Size halves into 7x7\n",
    "\n",
    "\t\t#Layer3\n",
    "\t\tself.conv3 = nn.Conv2d(in_channels=64,out_channels=64,kernel_size=3)\n",
    "\n",
    "\t\t#Layer4\n",
    "\t\tself.flatten = nn.Flatten()\n",
    "\n",
    "\t\t#Layer5\n",
    "\t\tself.fc1 = nn.Linear(in_features=64*3*3,out_features=64)\n",
    "\t\tself.relu3 = nn.ReLU()\n",
    "\n",
    "\t\t#Layer6\n",
    "\t\tself.fc2 = nn.Linear(in_features=64,out_features=26)\n",
    "\n",
    "\tdef forward(self,x):\n",
    "\n",
    "\t\t#Pass through Layer1\n",
    "\t\tx = self.pool1(self.relu1(self.conv1(x)))\n",
    "\n",
    "\t\t#Pass through Layer2\n",
    "\t\tx = self.pool2(self.relu2(self.conv2(x)))\n",
    "\n",
    "\t\t#Pass through Layer3\n",
    "\t\tx = self.conv3(x)\n",
    "\n",
    "\t\t#Pass through Layer4\n",
    "\t\tx = self.flatten(x)\n",
    "\n",
    "\t\t#Pass through Layer5\n",
    "\t\tx = self.relu3(self.fc1(x))\n",
    "\n",
    "\t\t#Pass through Layer6\n",
    "\t\tx = self.fc2(x)\n",
    "\n",
    "\t\t#Return Prediction\n",
    "\t\treturn x\n",
    "\n",
    "#Create and print summary\t\n",
    "print(\"Creating EMNIST Model...\")\n",
    "model = EMNISTModel().to(device)\n",
    "print(\"Model Created\")\n",
    "\n",
    "print(\"Model Summary: \")\n",
    "summary(model,input_size=(1,28,28))\n",
    "\n",
    "#Compile model\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "360e44df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model...\n",
      "Epoch: 1/30 | Training Loss: 0.557 | Validation Loss: 0.291 | Accuracy: 90.481%\n",
      "Validation loss has improved at epoch 1. Model Saved!\n",
      "Epoch: 2/30 | Training Loss: 0.264 | Validation Loss: 0.249 | Accuracy: 91.644%\n",
      "Validation loss has improved at epoch 2. Model Saved!\n",
      "Epoch: 3/30 | Training Loss: 0.223 | Validation Loss: 0.235 | Accuracy: 92.514%\n",
      "Validation loss has improved at epoch 3. Model Saved!\n",
      "Epoch: 4/30 | Training Loss: 0.202 | Validation Loss: 0.210 | Accuracy: 93.188%\n",
      "Validation loss has improved at epoch 4. Model Saved!\n",
      "Epoch: 5/30 | Training Loss: 0.185 | Validation Loss: 0.218 | Accuracy: 92.769%\n",
      "Validation loss has not improved. Patience:1/5\n",
      "Epoch: 6/30 | Training Loss: 0.171 | Validation Loss: 0.204 | Accuracy: 93.346%\n",
      "Validation loss has improved at epoch 6. Model Saved!\n",
      "Epoch: 7/30 | Training Loss: 0.161 | Validation Loss: 0.196 | Accuracy: 93.394%\n",
      "Validation loss has improved at epoch 7. Model Saved!\n",
      "Epoch: 8/30 | Training Loss: 0.154 | Validation Loss: 0.193 | Accuracy: 93.615%\n",
      "Validation loss has improved at epoch 8. Model Saved!\n",
      "Epoch: 9/30 | Training Loss: 0.146 | Validation Loss: 0.191 | Accuracy: 93.784%\n",
      "Validation loss has improved at epoch 9. Model Saved!\n",
      "Epoch: 10/30 | Training Loss: 0.138 | Validation Loss: 0.204 | Accuracy: 93.284%\n",
      "Validation loss has not improved. Patience:1/5\n",
      "Epoch: 11/30 | Training Loss: 0.133 | Validation Loss: 0.208 | Accuracy: 93.269%\n",
      "Validation loss has not improved. Patience:2/5\n",
      "Epoch: 12/30 | Training Loss: 0.127 | Validation Loss: 0.198 | Accuracy: 93.639%\n",
      "Validation loss has not improved. Patience:3/5\n",
      "Epoch: 13/30 | Training Loss: 0.121 | Validation Loss: 0.193 | Accuracy: 93.716%\n",
      "Validation loss has not improved. Patience:4/5\n",
      "Epoch: 14/30 | Training Loss: 0.117 | Validation Loss: 0.213 | Accuracy: 93.462%\n",
      "Validation loss has not improved. Patience:5/5\n",
      "Early stopping triggered!\n",
      "Training Complete\n"
     ]
    }
   ],
   "source": [
    "#Training and saving the model\n",
    "\n",
    "print(\"Training Model...\")\n",
    "epochs = 30\n",
    "patience = 5\n",
    "counter = 0\n",
    "MinValidationLoss = float('inf')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\t#Train Loop\n",
    "\n",
    "\t#Set model to training mode\n",
    "\tmodel.train()\n",
    "\tTrainLoss = 0.0\n",
    "\n",
    "\tfor i,data in enumerate(TrainLoader,0):\n",
    "\t\tinputs,labels = data[0].to(device),data[1].to(device)\n",
    "\n",
    "\t\t#Zero the parameter gradients\n",
    "\t\toptimizer.zero_grad()\n",
    "\n",
    "\t\t#Forward pass\n",
    "\t\toutputs = model(inputs)\n",
    "\n",
    "\t\t#Calculate loss\n",
    "\t\tloss = loss_function(outputs,labels)\n",
    "\n",
    "\t\t#Backward pass\n",
    "\t\tloss.backward()\n",
    "\n",
    "\t\t#Update weights\n",
    "\t\toptimizer.step()\n",
    "\n",
    "\t\t#Update loss\n",
    "\t\tTrainLoss += loss.item()\n",
    "\t\n",
    "\t#Validation Loop\n",
    "\tmodel.eval()\n",
    "\tValidationLoss = 0.0\n",
    "\tcorrect = 0\n",
    "\ttotal = 0\n",
    "\n",
    "\twith torch.no_grad():\n",
    "\t\tfor data in TestLoader:\n",
    "\t\t\timages,labels = data[0].to(device),data[1].to(device)\n",
    "\t\t\toutputs = model(images)\n",
    "\t\t\tloss = loss_function(outputs,labels)\n",
    "\t\t\tValidationLoss += loss.item()\n",
    "\n",
    "\t\t\t_,predicted = torch.max(outputs.data,1)\n",
    "\t\t\ttotal += labels.size(0)\n",
    "\t\t\tcorrect += (predicted == labels).sum().item()\n",
    "\n",
    "\t\tacc = 100*correct/total\n",
    "\t\tprint(f\"Epoch: {epoch+1}/{epochs} | \"\n",
    "\t\t\tf\"Training Loss: {TrainLoss/len(TrainLoader):.3f} | \"\n",
    "\t\t\tf\"Validation Loss: {ValidationLoss / len(TestLoader):.3f} | \"\n",
    "\t\t\tf\"Accuracy: {acc:.3f}%\")\n",
    "\t\t\n",
    "\t\tif ValidationLoss < MinValidationLoss:\n",
    "\t\t\tMinValidationLoss = ValidationLoss\n",
    "\t\t\tcounter = 0\n",
    "\t\t\ttorch.save(model.state_dict(),\"EMNISTModel.pth\")\n",
    "\t\t\tprint(f\"Validation loss has improved at epoch {epoch+1}. Model Saved!\")\n",
    "\t\telse:\n",
    "\t\t\tcounter += 1\n",
    "\t\t\tprint(f\"Validation loss has not improved. Patience:{counter}/{patience}\")\n",
    "\t\t\n",
    "\t\tif counter >= patience:\n",
    "\t\t\tprint(\"Early stopping triggered!\")\n",
    "\t\t\tbreak\n",
    "\t\t\n",
    "print(\"Training Complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b2021dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model with inbuilt dataset...\n",
      "Test Accuracy: 93.784%\n",
      "Test Loss: 0.191\n"
     ]
    }
   ],
   "source": [
    "#Testing Model\n",
    "\n",
    "print(\"Testing model with inbuilt dataset...\")\n",
    "\n",
    "model.load_state_dict(torch.load(\"EMNISTModel.pth\"))\n",
    "\n",
    "TestLoss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "\tfor images, labels in TestLoader:\n",
    "\n",
    "\t\t#Move data to device\n",
    "\t\timages,labels = images.to(device),labels.to(device)\n",
    "\n",
    "\t\t#Forward pass\n",
    "\t\toutputs = model(images)\n",
    "\n",
    "\t\t#Calculate loss\n",
    "\t\tloss = loss_function(outputs,labels)\n",
    "\t\tTestLoss += loss.item()\n",
    "\n",
    "\t\t#Get predicted class\n",
    "\t\t_,predicted = torch.max(outputs.data,1)\n",
    "\n",
    "\t\t#Update total and correct counts\n",
    "\t\ttotal += labels.size(0)\n",
    "\t\tcorrect += (predicted == labels).sum().item()\n",
    "\t\n",
    "#Test Results\n",
    "\n",
    "FinalLoss = TestLoss/len(TestLoader)\n",
    "FinalAcc = 100*correct/total\n",
    "\n",
    "print(f\"Test Accuracy: {FinalAcc:.3f}%\")\n",
    "print(f\"Test Loss: {FinalLoss:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
