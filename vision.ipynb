{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe9a0af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from crossword_algorithm import find_words\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77c60531",
   "metadata": {},
   "outputs": [],
   "source": [
    "#while True:\n",
    "    # ret, frame3 = video.read()\n",
    "\n",
    "    # frame4 = cv2.cvtColor(frame3, cv2.COLOR_BGR2GRAY)\n",
    "    # #frame = cv2.blur(frame4, (100,1))\n",
    "\n",
    "    # frame = cv2.adaptiveThreshold(frame4, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 21, 7)\n",
    "\n",
    "    # cv2.imshow(\"vid\", frame)\n",
    "\n",
    "    # if cv2.waitKey(4) & 0xFF == ord('q'):\n",
    "    #     break\n",
    "\n",
    "# video.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51ffdc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "image2 = cv2.imread(\"image_samples/word_search_school.png\")\n",
    "image = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "#ret, image = cv2.threshold(image, 100, 255, cv2.THRESH_BINARY_INV)\n",
    "image = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 33, 25)\n",
    "\n",
    "image = cv2.blur(image, (2,2))\n",
    "\n",
    "contours, _ = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "area = 0\n",
    "\n",
    "for cnt in contours:\n",
    "    area += cv2.contourArea(cnt)\n",
    "\n",
    "area = area/len(contours)\n",
    "\n",
    "letter_grid_coordinates = dict()\n",
    "y_top, y_bottom = -1,-1\n",
    "\n",
    "for i in range(len(contours)):\n",
    "    #cv2.drawContours(image2, cnt, -1, (255,0,0), 7 )\n",
    "    if cv2.contourArea(contours[i]) < 0.1*area:\n",
    "        continue\n",
    "    x, y, w, h = cv2.boundingRect(contours[i])\n",
    "    #cv2.rectangle(image2, (x - int(w*(0.45)), y - int(h*(0.45))), (x + w + int(w*(0.45)), y + h + int(h*(0.45))), (0, 255, 0), 2)\n",
    "\n",
    "    pushed = False\n",
    "\n",
    "    for key in letter_grid_coordinates.keys():\n",
    "        if y + w//2 in range(key[0], key[1]):\n",
    "            y_top, y_bottom = y, y+h\n",
    "            letter_grid_coordinates[key].append((x - int((w)*(0.25)), y - int(h*(0.25)), x + w + int(w*(0.25)), y + h + int(h*(0.25))))\n",
    "            pushed = True\n",
    "\n",
    "    if not pushed:\n",
    "        letter_grid_coordinates[(y, y+w)] = [(x - int(w*(0.25)), y - int(h*(0.25)), x + w + int(w*(0.25)), y + h + int(h*(0.25)))]\n",
    "    \n",
    "    #cv2.rectangle(image2, (x - int(w*(0.45)), y - int(h*(0.45))), (x + w + int(w*(0.45)), y + h + int(h*(0.45))), (0, 255, 0), 2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32166573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# video = cv2.VideoCapture(0)\n",
    "\n",
    "# while True:\n",
    "#     r, image2 = video.read()\n",
    "#     image = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "#     #ret, image = cv2.threshold(image, 100, 255, cv2.THRESH_BINARY_INV)\n",
    "#     image = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 33, 25)\n",
    "\n",
    "#     image = cv2.blur(image, (2,2))\n",
    "\n",
    "#     contours, _ = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "#     area = 0\n",
    "\n",
    "#     for cnt in contours:\n",
    "#         area += cv2.contourArea(cnt)\n",
    "\n",
    "#     area = area/len(contours)\n",
    "\n",
    "#     for i in range(len(contours)):\n",
    "#         #cv2.drawContours(image2, cnt, -1, (255,0,0), 7 )\n",
    "#         if cv2.contourArea(contours[i]) < 0.1*area:\n",
    "#             continue\n",
    "#         x, y, w, h = cv2.boundingRect(contours[i])\n",
    "#         cv2.rectangle(image2, (x - int(w*(0.45)), y - int(h*(0.45))), (x + w + int(w*(0.45)), y + h + int(h*(0.45))), (0, 255, 0), 2)\n",
    "\n",
    "#     cv2.imshow(\"hsf\", image2)\n",
    "#     cv2.imshow(\"hsf2\", image)\n",
    "\n",
    "#     cv2.waitKey(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2076fd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"font_identifier.keras\")\n",
    "letter_width = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8fa30e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"conv2d\" is incompatible with the layer: expected axis -1 of input shape to have value 1, but received input with shape (20, 1, 28, 28)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(20, 1, 28, 28, 1), dtype=float32)\n  • training=False\n  • mask=None\n  • kwargs=<class 'inspect._empty'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 34\u001b[0m\n\u001b[1;32m     30\u001b[0m     all_images\u001b[38;5;241m.\u001b[39mappend(img)\n\u001b[1;32m     32\u001b[0m all_images \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(all_images)\n\u001b[0;32m---> 34\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mall_images\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prediction \u001b[38;5;129;01min\u001b[39;00m prediction:\n\u001b[1;32m     37\u001b[0m     x\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mchr\u001b[39m(np\u001b[38;5;241m.\u001b[39margmax(prediction) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m65\u001b[39m))\n",
      "File \u001b[0;32m/opt/anaconda3/envs/testenv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/anaconda3/envs/testenv/lib/python3.10/site-packages/keras/src/layers/input_spec.py:227\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m axis, value \u001b[38;5;129;01min\u001b[39;00m spec\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m shape[axis] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[1;32m    224\u001b[0m             value,\n\u001b[1;32m    225\u001b[0m             \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    226\u001b[0m         }:\n\u001b[0;32m--> 227\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    228\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    229\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: expected axis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    230\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof input shape to have value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    231\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut received input with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    232\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    233\u001b[0m             )\n\u001b[1;32m    234\u001b[0m \u001b[38;5;66;03m# Check shape.\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"conv2d\" is incompatible with the layer: expected axis -1 of input shape to have value 1, but received input with shape (20, 1, 28, 28)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(20, 1, 28, 28, 1), dtype=float32)\n  • training=False\n  • mask=None\n  • kwargs=<class 'inspect._empty'>"
     ]
    }
   ],
   "source": [
    "cv2.imshow(\"hsf\", image2)\n",
    "cv2.imshow(\"hsf2\", image)\n",
    "cv2.waitKey(1000)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "crossword = list()\n",
    "\n",
    "for i in letter_grid_coordinates.keys():\n",
    "    letter_grid_coordinates[i] = sorted(letter_grid_coordinates[i], key=lambda x: x[0])\n",
    "    #print(letter_grid_coordinates[i])\n",
    "\n",
    "for i in reversed(letter_grid_coordinates.values()):\n",
    "    x = list()\n",
    "    for j in i:\n",
    "        x1, y1, x2, y2 = j\n",
    "        if not letter_width:\n",
    "            letter_width = y2 - y1\n",
    "        img = image[y1:y2, x1:x2]\n",
    "        img = Image.fromarray(img)\n",
    "        img.thumbnail((28, 28), Image.Resampling.LANCZOS)\n",
    "\n",
    "        pillow_image = Image.new(\"L\", (28, 28), 0)\n",
    "        pillow_image.paste(img, ((28 - img.size[0]) // 2, (28 - img.size[1]) // 2))\n",
    "\n",
    "        img = np.array(pillow_image).reshape((1,28,28,1))\n",
    "        img = img/255.0\n",
    "        \n",
    "        prediction = model.predict(img)\n",
    "        x.append(chr(np.argmax(prediction) + 65))\n",
    "\n",
    "\n",
    "    crossword.append(x)\n",
    "\n",
    "# j = list(letter_grid_coordinates.values())[8][17]\n",
    "\n",
    "# x1, y1, x2, y2 = j\n",
    "# img = image[y1:y2, x1:x2]\n",
    "# img = cv2.resize(img, (28, 28))\n",
    "# cv2.imshow(str(x1), img)\n",
    "# img = img.reshape((-1,28,28,1))\n",
    "# img = img/255.0\n",
    "# prediction = model.predict(img)\n",
    "# print(chr(np.argmax(prediction) + 65))\n",
    "\n",
    "# for i in letter_grid_coordinates.keys():\n",
    "#     print(len(letter_grid_coordinates[i]) , \"elements in\", i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28231503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#word_position = find_words(crossword, ['GARDEN', 'SUMMER', 'SUNSHINE', 'SWIM', 'BOAT', 'CAMP', 'HIKE', 'PLAY', 'BEACH', 'JULY', 'AUGUST', 'PARK', 'PICNIC', 'POPSICLE', 'ICECREAM', 'SHORTS', 'TRAVEL', 'DRESS', 'VACATION', 'SEASON'])\n",
    "\n",
    "\n",
    "word_position = find_words(crossword, [\n",
    "    'DRAMA', 'HISTORY', 'NUMBERS', 'SCIENCE', 'ART',\n",
    "    'ELEMENTARY', 'HOMEWORK', 'PENCIL', 'SOCIALSTUDIES',\n",
    "    'BACKPACK', 'ENGLISH', 'LANGUAGEARTS', 'PHYSICALEDUCATION',\n",
    "    'SPELLING', 'BOOKS', 'FRIENDS', 'LEARN', 'READING',\n",
    "    'STUDENTS', 'CLASSROOM', 'GEOGRAPHY', 'LIBRARY',\n",
    "    'RECESS', 'SUBJECTS', 'CRAYONS', 'GRADES',\n",
    "    'MATH', 'SCHOOL', 'TEACHER', 'DESK', 'HEALTH',\n",
    "    'MUSIC', 'SCISSORS', 'WRITING'\n",
    "])\n",
    "\n",
    "image2_cpy = image2.copy()\n",
    "\n",
    "for x in word_position:\n",
    "    start_word_pos, end_word_pos = x\n",
    "    k = list(reversed(letter_grid_coordinates.values()))\n",
    "    start = k[start_word_pos[0]][start_word_pos[1]]\n",
    "    end = k[end_word_pos[0]][end_word_pos[1]]\n",
    "\n",
    "    color = random.sample(range(150, 200), 3)\n",
    "\n",
    "    #result = cv2.line(result, ((start[0] + start[2]) // 2 - 10, (start[1] + start[3]) // 2 - 10) , ((end[0] + end[2]) // 2 + 10, (end[1] + end[3]) // 2 + 10) , color, 1)\n",
    "    result = cv2.line(image2, ((start[0] + start[2]) // 2 - 2, (start[1] + start[3]) // 2 - 2) , ((end[0] + end[2]) // 2 + 2, (end[1] + end[3]) // 2 + 2) , color, letter_width)\n",
    "    \n",
    "alpha = 0.3\n",
    "result = cv2.addWeighted(result, alpha, image2_cpy, 1 - alpha, 0)\n",
    "\n",
    "cv2.imshow(\"solved\", result)\n",
    "cv2.waitKey(10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
